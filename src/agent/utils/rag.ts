import fs from "fs";
import path from "path";
import crypto from "crypto";
import { MemoryVectorStore } from "@langchain/classic/vectorstores/memory";
import { RecursiveCharacterTextSplitter } from "@langchain/textsplitters";
import { Document } from "@langchain/core/documents";
import { HuggingFaceTransformersEmbeddings } from "@langchain/community/embeddings/huggingface_transformers";
import { loadAgentConfig } from "./configLoader"; // üëà –ò–ú–ü–û–†–¢ –ö–û–ù–§–ò–ì–ê

// –¢–∏–ø—ã –¥–ª—è –Ω–∞—à–µ–≥–æ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫—ç—à–∞
interface CacheEntry {
  hash: string;
  chunks: {
    pageContent: string;
    metadata: any;
    vector: number[];
  }[];
}

type RagCache = Record<string, CacheEntry>;

function getFileHash(filePath: string): string {
  const content = fs.readFileSync(filePath, "utf-8");
  return crypto.createHash("md5").update(content).digest("hex");
}

// üëà –£–õ–£–ß–®–ï–ù–ù–´–ô –†–ï–ö–£–†–°–ò–í–ù–´–ô –û–ë–•–û–î
function getAllFiles(dirPath: string, arrayOfFiles: string[] = []) {
  if (!fs.existsSync(dirPath)) return arrayOfFiles;

  const files = fs.readdirSync(dirPath);
  files.forEach((file) => {
    const fullPath = path.join(dirPath, file);
    if (fs.statSync(fullPath).isDirectory()) {
      // –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–∞–ø–∫–∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
      if (!["node_modules", ".git", ".agent", "dist", "build", "__pycache__"].includes(file) && !file.startsWith(".")) {
        arrayOfFiles = getAllFiles(fullPath, arrayOfFiles);
      }
    } else {
      // üëà –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô –°–ü–ò–°–û–ö –†–ê–°–®–ò–†–ï–ù–ò–ô
      const validExtensions = [".vue", ".ts", ".js", ".tsx", ".jsx", ".py", ".go", ".rs", ".json", ".md"];
      if (validExtensions.includes(path.extname(file))) {
        arrayOfFiles.push(fullPath);
      }
    }
  });
  return arrayOfFiles;
}

export async function getContextViaRAG(workDir: string, task: string): Promise<string> {
  const agentDir = path.join(workDir, ".agent");
  const cachePath = path.join(agentDir, "rag-cache.json");
  
  // üëà –ó–ê–ì–†–£–ó–ö–ê –ö–û–ù–§–ò–ì–ê
  const config = loadAgentConfig(workDir);

  if (!fs.existsSync(agentDir)) fs.mkdirSync(agentDir, { recursive: true });

  let cache: RagCache = {};
  if (fs.existsSync(cachePath)) {
    try {
      cache = JSON.parse(fs.readFileSync(cachePath, "utf-8"));
    } catch (e) {
      cache = {};
    }
  }

  const embeddingsModel = new HuggingFaceTransformersEmbeddings({
    model: "Xenova/all-MiniLM-L6-v2",
  });

  // üëà –°–ë–û–† –§–ê–ô–õ–û–í –ò–ó –í–°–ï–• –ü–ê–ü–û–ö –ö–û–ù–§–ò–ì–ê
  let allFiles: string[] = [];
  config.contextFiles.forEach(folder => {
    const targetPath = path.join(workDir, folder);
    if (fs.existsSync(targetPath)) {
      // –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ñ–∏–≥–µ —É–∫–∞–∑–∞–Ω –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–∞–π–ª, –∞ –Ω–µ –ø–∞–ø–∫–∞
      if (fs.statSync(targetPath).isFile()) {
        allFiles.push(targetPath);
      } else {
        allFiles = getAllFiles(targetPath, allFiles);
      }
    }
  });

  const newCache: RagCache = {};
  let updatedFilesCount = 0;

  console.log(`üîç [RAG] –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π: ${config.contextFiles.join(", ")}...`);

  for (const file of allFiles) {
    const relativePath = path.relative(workDir, file);
    const currentHash = getFileHash(file);

    if (cache[relativePath] && cache[relativePath].hash === currentHash) {
      newCache[relativePath] = cache[relativePath];
      continue;
    }

    updatedFilesCount++;
    const content = fs.readFileSync(file, "utf-8");
    const doc = new Document({ pageContent: content, metadata: { source: relativePath } });

    const splitter = new RecursiveCharacterTextSplitter({ chunkSize: 1000, chunkOverlap: 200 });
    const splittedDocs = await splitter.splitDocuments([doc]);

    const chunksData: { pageContent: string; metadata: any; vector: number[] }[] = [];
    for (const chunk of splittedDocs) {
      const vector = await embeddingsModel.embedQuery(chunk.pageContent);
      chunksData.push({
        pageContent: chunk.pageContent,
        metadata: chunk.metadata,
        vector: vector
      });
    }

    newCache[relativePath] = {
      hash: currentHash,
      chunks: chunksData
    };
  }

  fs.writeFileSync(cachePath, JSON.stringify(newCache));

  if (updatedFilesCount > 0) {
    console.log(`‚úÖ [RAG] –û–±–Ω–æ–≤–ª–µ–Ω—ã –≤–µ–∫—Ç–æ—Ä—ã –¥–ª—è ${updatedFilesCount} —Ñ–∞–π–ª–æ–≤.`);
  }

  const allVectors: number[][] = [];
  const allDocuments: Document[] = [];

  for (const fileData of Object.values(newCache)) {
    for (const chunk of fileData.chunks) {
      allVectors.push(chunk.vector);
      allDocuments.push(new Document({
        pageContent: chunk.pageContent,
        metadata: chunk.metadata
      }));
    }
  }

  if (allDocuments.length === 0) return "–ö–æ–¥–æ–≤–∞—è –±–∞–∑–∞ –ø—É—Å—Ç–∞ –≤ —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ö.";

  const vectorStore = new MemoryVectorStore(embeddingsModel);
  await vectorStore.addVectors(allVectors, allDocuments);

  console.log("üîç [RAG] –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞...");
  const results = await vectorStore.similaritySearch(task, 4); // –£–≤–µ–ª–∏—á–∏–ª –¥–æ 4 –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

  let contextStr = "";
  results.forEach((res, i) => {
    contextStr += `\n--- –§–†–ê–ì–ú–ï–ù–¢ ${i + 1} [–§–ê–ô–õ: ${res.metadata.source}] ---\n${res.pageContent}\n`;
  });

  return contextStr;
}